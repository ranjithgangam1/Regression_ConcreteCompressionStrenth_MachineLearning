---
title: "BANA7038_Final"
author: "bollara,taridaar,anchurmu,gangamrh"
date: "December 2, 2015"
output: html_document
---

Summary:

The Concrete Compressive strentgh  is a dataset consisting all the following attributes:
cement, blast furnace slag, fly ash,water, superplasticizer, coarse aggregate, and fine aggregate.

The concrete compressive strength is a highly nonlinear function of age and ingredients. We built a model for calculatig the concrete compressive strength.

Backward elimination is followed to optimise the model to get best concrete compressive strength.

polynomial Regression is seen with Age variable and hence its higher degree can be used to get optimised model.

Multicollineariy is seen with Age variable and its higher degrees. To remove Centers are shifted and ridge regression is tried for degree 3 to remove multi collinearity.

Min square residuals and MallowCp is calculated and seen along with R-square values to confirm the model valuation.

ConcreteCompressiveStrength ~ 30.51 + 0.106 * Cement + 0.087 * BlastFurnaceSlag + 0.064 * FlyAsh - 0.02 * Water + 0.179 * Superplasticizer + 0.278 * Age_centered - 0.00806 * I(Age_centered^2)


```{r echo=FALSE}
rm(list=ls())
setwd("/Users/raviteja/Documents/UC/DAM/Final/")
ip_data = read.csv("Concrete_Data.csv", header = T)
library(leaps)
library(psych)
library(car)
library(genridge)
library(pls)
library(ridge)
library(MASS)
```

**Function which returns the Model Evaluators for input model**

```{r}
ModelEvaluators <- function(RegModel,x,n,p){
  
# Calculate Predicted-RSquared value

PRESS_res=RegModel$residuals/(1 - lm.influence(RegModel)$hat)
PRESS=sum(PRESS_res^2)
SST = sum((ip_data$ConcreteCompressiveStrength-mean(ip_data$ConcreteCompressiveStrength))^2)
R_square_pred=1-PRESS/SST

# Calcuate SSRes

SSRes=sum((ip_data$ConcreteCompressiveStrength-RegModel$fitted.values)^2)
MSRes = SSRes / (n-p)
#Res_Std_Error = sqrt(deviance(RegModel)/df.residual(RegModel))

# Calcuate F-Statistic

FStatistic = summary(RegModel)$fstatistic[1]

# R-Square

R_square = summary(RegModel)$r.square

# Adjusted R-Squared

Adj_R_squared = summary(RegModel)$adj.r.squared

AIC = extractAIC(RegModel)
BIC = extractAIC(RegModel, k = log(n))

MallowsCp = leaps( x=x, y=ip_data$ConcreteCompressiveStrength, method="Cp")

return(c(R_square,Adj_R_squared,R_square_pred,FStatistic,MSRes,n,p,AIC,BIC,MallowsCp))
}

```

```{r echo=FALSE}
names(ip_data)
sapply(ip_data, class)
pairs(ip_data, main="Concrete Compressive Strength")
summary(ip_data)

pairs.panels(ip_data, main="Correlation plot for all variables")

```

**Model Building with Backward elimination**
```{r results=FALSE}
n = nrow(ip_data)

x1 = cbind(ip_data$Cement, ip_data$BlastFurnaceSlag, ip_data$FlyAsh, ip_data$Water, ip_data$Superplasticizer, ip_data$CoarseAggregate,ip_data$FineAggregate, ip_data$Age)

model1 <- lm(ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + CoarseAggregate + FineAggregate + Age, data=ip_data)
summary(model1)

M1 = ModelEvaluators(model1,x1,n,9)
```

Since t-value for FineAggregate and CoarseAggregate are very small. We will be removing them to optimize model.
F-statistic values seems to be small and R-square values. 

```{r results=FALSE}
model2 <- lm(ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + Age, data=ip_data)
x2 = cbind(ip_data$Cement, ip_data$BlastFurnaceSlag, ip_data$FlyAsh, ip_data$Water, ip_data$Superplasticizer, ip_data$Age)
summary(model2)
vif(model2)
M2 = ModelEvaluators(model2,x2,n,7)
```
Since we have seen same R-square value, we can confirm FineAggregate and CoarseAggregate are not contributing much to the model.<TBD>

From Pairs plot it looks like a polynomial for variable Age with ConcreteCompressiveStrength
**Polynomial Test**
```{r echo=FALSE}
plot(ip_data$Age, ip_data$ConcreteCompressiveStrength)
```


  Above graph looks like there exists a polynomial with variable Age.
```{r echo=FALSE}
plot(ip_data$Age^2,model2$residuals )
```
From the above residual plot it can be observed that there is some pattern.Hence, adding age^2 as a regressor variabel might fit the model better.

**Test by Adding Age^2**
```{r results=FALSE}
model3 <- lm(ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + Age+ I(Age^2), data=ip_data)
x3 = cbind(ip_data$Cement, ip_data$BlastFurnaceSlag, ip_data$FlyAsh, ip_data$Water, ip_data$Superplasticizer, ip_data$Age + (ip_data$Age^2))
summary(model3)
vif(model3)

M3 = ModelEvaluators(model3,x3,n,8)
```
Adding Age square gives better R-square value. But the high vif(>10) value indicates there exists multicollinearity. This multicollinearity is removed by shifting centers.
<TBD>

**Test by Adding Age^3**
```{r results=FALSE}
model4 <- lm(ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + Age+ I(Age^2) + I(Age^3), data=ip_data)
x4 = cbind(ip_data$Cement, ip_data$BlastFurnaceSlag, ip_data$FlyAsh, ip_data$Water, ip_data$Superplasticizer, ip_data$Age + (ip_data$Age^2) + (ip_data$Age^3))
summary(model4)
vif(model4)

M4 = ModelEvaluators(model4,x4,n,9)
```
Here we didnt see much optimisation by addng Age^3. And also there is very high collinerity seen as result of vif. We should try Centers shift and Ridge Regression.

```{r}
ip_data$Age_centered <- ip_data$Age-mean(ip_data$Age)
model5 <- lm(ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + Age_centered + I(Age_centered^2), data=ip_data)
x5 = cbind(ip_data$Cement, ip_data$BlastFurnaceSlag, ip_data$FlyAsh, ip_data$Water, ip_data$Superplasticizer, ip_data$Age_centered, I(ip_data$Age_centered^2))
summary(model5)
vif(model5)
 
M5 = ModelEvaluators(model5,x5,n,8)

ConcreteModel <- model5
```

**MODEL EVALUATION**

Model # | Co-variates List | Multiple R_Squared | Adjusted R_Squared | Predicted R_Squared | F-Statistic | MSRes | n | p | AIC | BIC | MallowsCp
--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
1 | All Co-variates | `r M1[1]` | `r M1[2]` | `r M1[3]` | `r M1[4]` | `r M1[5]` | `r M1[6]` | `r M1[7]` | `r M1[8]` | `r M1[9]` | `r M1[10]`
2 | Remove Two Variables | `r M2[1]` | `r M2[2]` | `r M2[3]` | `r M2[4]` | `r M2[5]` | `r M2[6]` | `r M2[7]` | `r M2[8]` | `r M2[9]` | `r M2[10]`
3 | Add Age^2 | `r M3[1]` | `r M3[2]` | `r M3[3]` | `r M3[4]` | `r M3[5]` | `r M3[6]` | `r M3[7]` | `r M3[8]` | `r M3[9]` | `r M3[10]`
4 | Add Age^3 | `r M4[1]` | `r M4[2]` | `r M4[3]` | `r M4[4]` | `r M4[5]` | `r M4[6]` | `r M4[7]` | `r M4[8]` | `r M4[9]` | `r M4[10]`
5 | **Shift Age's Centers** | **`r M5[1]`** | **`r M5[2]`** | **`r M5[3]`** | **`r M5[4]`** | **`r M5[5]`** | **`r M5[6]`** | **`r M5[7]`** | **`r M5[8]`** | **`r M5[9]`** | **`r M5[10]`**

From analysing the above table, following observations helped us in choosing the highlighted model

1) A high value for R_squared, Adj_ R_Squared and Pred_R_squared is desired.
2) AIC value, near to number of parameters+1 is desired, it helps us in estimating the quality of each model. Its value gives us an estimate of trade-off between goodness of fit of the model and model complexity.
3) Small value for BIC is preferred. It gives similar value as AIC, but the penality term is larger in BIC.
4) Adding AgeË†3 as a regressor variable increases R^2 value but the VIF values are very high and is not desired.Hence model4 is not considered.
5)Low values for MSRes is desired.

** Test by BOXcox method**
```{r}
require(MASS)

boxcox(model3,seq(0, 1, 0.1))

ip_data <- cbind(ip_data, ip_data$ConcreteCompressiveStrength^0.72)
names(ip_data)[11] <- "Yprime"
BoxcoxModel<-lm(Yprime~Cement+BlastFurnaceSlag+FlyAsh+Water+Superplasticizer+Age_centered+I(Age_centered^2),data=ip_data)
boxcox(BoxcoxModel)
vif(BoxcoxModel)

M5 = ModelEvaluators(BoxcoxModel,x3,n,9)

summary(BoxcoxModel)
```

We didn't see much optimised value with this Boxcox Model.

**Residual Plots**

**Residual Plots against Regressors not in the Model**

```{r echo=FALSE}
par(mfrow=c(1,2))
plot(ip_data$CoarseAggregate,ConcreteModel$residuals,pch=20)
plot(ip_data$FineAggregate,ConcreteModel$residuals,pch=20)
par(mfrow=c(1,1))
```


  There is no concrete pattern, therefore the regressor variables not in the model, aren't significant enough to be added in the model. The model is fine.

**Residual Plots against Regressors in the Model**

```{r echo=FALSE}
par(mfrow=c(1,3))
plot(ip_data$Cement,ConcreteModel$residuals,pch=20)
plot(ip_data$BlastFurnaceSlag,ConcreteModel$residuals,pch=20)
plot(ip_data$FlyAsh,ConcreteModel$residuals,pch=20)
plot(ip_data$Water,ConcreteModel$residuals,pch=20)
plot(ip_data$Superplasticizer,ConcreteModel$residuals,pch=20)
plot(ip_data$Age_centered,ConcreteModel$residuals,pch=20)
par(mfrow=c(1,1))
```


  There is no definite pattern, therefore the regressor variables of the model, explained the variation in data well.


```{r echo=FALSE}
plot(ip_data$ConcreteCompressiveStrength,ConcreteModel$residuals,pch=20, main = "Residual Plots against Fitted values")
```

There is absolutely no pattern, the model is satisfactory.

```{r echo=FALSE}
ridgeModel <- lm.ridge(ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + Age_centered + I(Age_centered^2) + I(Age_centered^3), data=ip_data, lambda = seq(0,1,0.05))
summary(ridgeModel)
select(ridgeModel)

y <- ip_data[,"ConcreteCompressiveStrength"]
X0 <- model.matrix(ConcreteModel)[,-1]

aridge <- ridge(y, X0, lambda=seq(0,1,0.05))
traceplot(aridge)
```

  Ridge regression didnt help much for stablising vif value. Hence this model is not considered.
```{r echo=FALSE}

# Compute the Coefficient Estimates

Intercept = summary(ConcreteModel)$coef[1,1]
CementEstimate = summary(ConcreteModel)$coef[2,1]
BlastFurnanceSlagEstimate = summary(ConcreteModel)$coef[3,1]
FlyAshEstimate = summary(ConcreteModel)$coef[4,1]
WaterEstimate = summary(ConcreteModel)$coef[3,1]
SuperPlasticizerEstimate = summary(ConcreteModel)$coef[4,1]
AgeCenteredEstimate = summary(ConcreteModel)$coef[3,1]
AgeSqCenteredEstimate = summary(ConcreteModel)$coef[4,1]

# Calculate the size of Dataset

n = nrow(ip_data)

tB1HatLCI = (summary(ConcreteModel)$coef[2,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[2,2]))

tB1HatUCI = (summary(ConcreteModel)$coef[2,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[2,2]))

tB2HatLCI = (summary(ConcreteModel)$coef[3,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[3,2]))

tB2HatUCI = (summary(ConcreteModel)$coef[3,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[3,2]))

tB3HatLCI = (summary(ConcreteModel)$coef[4,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[4,2]))

tB3HatUCI = (summary(ConcreteModel)$coef[4,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[4,2]))

tB4HatLCI = (summary(ConcreteModel)$coef[5,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[5,2]))

tB4HatUCI = (summary(ConcreteModel)$coef[5,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[5,2]))

tB5HatLCI = (summary(ConcreteModel)$coef[6,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[6,2]))

tB5HatUCI = (summary(ConcreteModel)$coef[6,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[6,2]))

tB6HatLCI = (summary(ConcreteModel)$coef[7,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[7,2]))

tB6HatUCI = (summary(ConcreteModel)$coef[7,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[7,2]))

tB7HatLCI = (summary(ConcreteModel)$coef[8,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[8,2]))

tB7HatUCI = (summary(ConcreteModel)$coef[8,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[8,2]))

tB0HatLCI = (summary(ConcreteModel)$coef[1,1]) - (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[1,2]))

tB0HatUCI = (summary(ConcreteModel)$coef[1,1]) + (abs(qt(0.025,(n-7))) * (summary(ConcreteModel)$coef[1,2]))

```

**Coefficient Estimates and their Confidence Intervals obtained from Model**

Coefficients | Estimated Value | Lower Bound | Upper Bound
--- | --- | --- | ---
Intercept ($\beta_0$) | `r abs(Intercept)` | `r tB0HatLCI` | `r tB0HatUCI`
CementEstimate($\beta_1$) | `r CementEstimate` | `r tB1HatLCI` | `r tB1HatUCI`
BlastFurnanceSlagEstimate ($\beta_2$) | `r BlastFurnanceSlagEstimate` | `r tB2HatLCI` | `r tB2HatUCI`
FlyAshEstimate ($\beta_3$) | `r FlyAshEstimate` | `r tB3HatLCI` | `r tB3HatUCI`
WaterEstimate ($\beta_4$) | `r WaterEstimate` | `r tB4HatLCI` | `r tB4HatUCI`
SuperPlasticizerEstimate ($\beta_5$) | `r SuperPlasticizerEstimate` | `r tB5HatLCI` | `r tB5HatUCI`
AgeCenteredEstimate ($\beta_6$) | `r AgeCenteredEstimate` | `r tB6HatLCI` | `r tB6HatUCI`
AgeSqCenteredEstimate ($\beta_7$) | `r AgeSqCenteredEstimate` | `r tB7HatLCI` | `r tB7HatUCI`

The 95% Confidence Intervals of Coefficient Estimates given above, is the Average/Estimated value of the Coefficients. So, with 95% confidence we say that the values of these estimates fall within the interval specified for any sample chosen. And only 5% value of the estimates, may fall outside the confidence interval.




```{r echo=FALSE}

attach(ip_data)
SST=sum((ConcreteCompressiveStrength-mean(ConcreteCompressiveStrength))^2)
SSRes=sum((ConcreteCompressiveStrength-ConcreteModel$fitted.values)^2)
SSR=sum((ConcreteModel$fitted.values-mean(ConcreteCompressiveStrength))^2)
detach(ip_data)

```
Measure | Value
--- | ---
SST   | **`r SST`** 
SSRes | **`r SSRes`** 
SSR   | **`r SSR`**

Total Sums of Squares, SST is the Total Variation in the data. SST, value is fixed, irrespective of the model. SST = SSR + SSRes.

Since we have a very low value of SSRes when compared to SSR here, the variation in response variable/data that can be explained by the model is more than the variation that cannot be explained. It is desired to have low value for SSRes and high value for SSR. Hence, this model evolve as the best fit for the data.

**ANOVA Results for the Model & F-Test**

```{r echo=FALSE}

# Analysis of Variance - to Obtain F-Statistic Value

anova(ConcreteModel)

FStatistic = SSR/2 / (SSRes/(n-3-1))

pValueFStatistic = 1-pf(FStatistic,2,n-3-1)

FThreshold = qf(.95, df1=2, df2=n-3-1)

```

**Inference**

Here F-statistic with value **`r FStatistic`**, is greater than the F-Threhold value of `r FThreshold`, which is computed by *qf(.95, df1=2, df2=n-7-1)*. Also the p-value is very less in magnitude. Hence, Null Hypothesis **H0: $\beta_1$ = $\beta_2$ = $\beta_3$ = $\beta_4$ = $\beta_5$ = $\beta_6$ = $\beta_7$= 0** is **REJECTED**, and the model is highly significant.

The Value of **R-Square** is **`r M4[1]`**, it indicates the explanatory power of the model to explain the response variable. So, ~75% of variation in the response variable is explained by the model.

Adjusted R_square penalizes the model for inclusion of insignificant variables. Here, its high in comparision with R_squared and is desired. Similarly, high value for Predicted R_square is desired. It determines how well the model predicts the removed observation.

**Compute 95% Confidence Intervals for Fitted Values(Mean Responses)**

```{r}

ConfValues = predict(ConcreteModel,ip_data,level=.95,interval="confidence",type="response")

```

  The final Polynomial Regression model is:</br>
<font color = "red"> ConcreteCompressiveStrength ~ Cement + BlastFurnaceSlag + FlyAsh + Water + Superplasticizer + Age_centered + I(Age_centered^2)</font></b>